================================================================================
EXPLICACIÓN: ¿QUÉ ES Y CÓMO FUNCIONA modelo.pkl?
================================================================================

¿QUÉ ES modelo.pkl?
===================
modelo.pkl es un archivo que contiene un modelo de Machine Learning ENTRENADO
y guardado en disco. El ".pkl" significa "pickle", un formato de serialización
de Python que permite guardar objetos complejos de forma compacta.

En nuestro caso, modelo.pkl contiene:
- Un modelo Random Forest entrenado
- Todos sus parámetros internos (pesos, configuración, etc.)
- La capacidad de hacer predicciones sin necesidad de reentrenar


¿POR QUÉ NECESITAMOS modelo.pkl?
=================================
1. REUTILIZACIÓN: Entrenamos el modelo UNA sola vez en el notebook
2. VELOCIDAD: No necesitamos reentrenar cada vez que usamos la app
3. PORTABILIDAD: Se puede compartir y usar en diferentes máquinas
4. EFICIENCIA: Evita usar datos grandes innecesariamente


================================================================================
¿CÓMO SE CREA modelo.pkl? (EN EL NOTEBOOK)
================================================================================

PASO 1: IMPORTAR LA LIBRERÍA joblib
====================================
En main.ipynb encontrarás:

```python
import joblib
```

Explicación:
- joblib es una librería que guarda y carga objetos de Python
- Es más eficiente que pickle para arrays numéricos grandes


PASO 2: ENTRENAR EL MODELO
===========================
En main.ipynb encontrarás:

```python
rf = RandomForestClassifier(class_weight="balanced", random_state=42)
rf.fit(X_train, y_train)
```

Explicación:
- RandomForestClassifier(): Crea el modelo (aún no entrenado)
- .fit(X_train, y_train): ENTRENA el modelo con los datos
  - X_train: 14 features numéricos
  - y_train: etiquetas (0 o 1, sin o con ictus)
- Después de fit(), el modelo interno tiene:
  - Pesos y parámetros aprendidos
  - Reglas de decisión en los árboles
  - Capacidad de predecir


PASO 3: USAR GridSearchCV (OPTIMIZACIÓN)
=========================================
En main.ipynb encontrarás:

```python
param_grid = {
    "n_estimators": [100, 200],
    "max_depth": [None, 5, 10],
    "min_samples_split": [2, 5]
}

grid = GridSearchCV(rf, param_grid, cv=5, scoring="recall")
grid.fit(X_train, y_train)

best_model = grid.best_estimator_
```

Explicación:
- GridSearchCV prueba TODAS las combinaciones de parámetros
- Encuentra el modelo que funciona MEJOR
- grid.best_estimator_ es el mejor modelo entrenado


PASO 4: GUARDAR EL MODELO EN DISCO
===================================
En main.ipynb encontrarás (última celda):

```python
import joblib

if 'grid' in globals() and hasattr(grid, 'best_estimator_'):
    best_model = grid.best_estimator_
elif 'rf' in globals():
    best_model = rf
elif 'model' in globals():
    best_model = model
else:
    best_model = None

if best_model is not None:
    joblib.dump(best_model, "modelo.pkl")
    print("Modelo guardado en 'modelo.pkl'")
else:
    print("No se encontró modelo para guardar.")
```

Explicación paso a paso:

A) Verificar qué modelo usar:
   - if 'grid' in globals()     → ¿Existe GridSearchCV?
     - Sí: usar el mejor modelo de la búsqueda
     - No: pasar al siguiente
   - elif 'rf' in globals()     → ¿Existe RandomForest?
     - Sí: usar ese
     - No: pasar al siguiente
   - elif 'model' in globals()  → ¿Existe Regresión Logística?
     - Sí: usar ese
     - No: best_model = None

B) Guardar en disco:
   - if best_model is not None  → Si encontramos un modelo
   - joblib.dump(best_model, "modelo.pkl")
     - dump() = "vuelca/guarda"
     - best_model = objeto a guardar
     - "modelo.pkl" = archivo donde guardar
   - print() = mensaje confirmando que se guardó


================================================================================
¿CÓMO FUNCIONA modelo.pkl INTERNAMENTE?
================================================================================

SERIALIZACIÓN (GUARDANDO):
==========================

Cuando ejecutas:
    joblib.dump(best_model, "modelo.pkl")

Sucede esto:

1. joblib toma el objeto Python (el modelo)
   ↓
2. Lo convierte a bytes (secuencia de números)
   ↓
3. Los bytes se escriben en el archivo "modelo.pkl"
   ↓
4. El archivo se guarda en disco

Resultado: un archivo .pkl que contiene el modelo completo


DESERIALIZACIÓN (CARGANDO):
============================

Cuando desde app.py ejecutas:
    model = joblib.load("modelo.pkl")

Sucede esto:

1. joblib abre el archivo "modelo.pkl"
   ↓
2. Lee los bytes del archivo
   ↓
3. Convierte los bytes de nuevo a un objeto Python
   ↓
4. Devuelve el objeto (el modelo) lista para usar

Resultado: la variable "model" contiene el modelo entrenado


ENTRE BAMBALINAS (ESTRUCTURA DE modelo.pkl):
=============================================

Dentro de modelo.pkl se almacena:

┌────────────────────────────────────────┐
│ RANDOM FOREST CLASSIFIER               │
├────────────────────────────────────────┤
│ - Número de árboles: 200               │
│ - Max depth: 10                        │
│ - Min samples split: 2                 │
│ - Random state: 42                     │
├────────────────────────────────────────┤
│ - ÁRBOL 1                              │
│   ├─ Decisión: if feature_5 > 0.5     │
│   ├─ Izquierda: ÁRBOL 1.1             │
│   └─ Derecha: ÁRBOL 1.2               │
│ - ÁRBOL 2                              │
│   ├─ Decisión: if feature_12 > 0.3    │
│   └─ ...                               │
│ - ÁRBOL 3, 4, 5, ... (hasta 200)       │
│                                        │
│ - Importancia de features (pesos)      │
│ - Otros parámetros internos            │
└────────────────────────────────────────┘


================================================================================
FLUJO COMPLETO: DEL NOTEBOOK A LA APP
================================================================================

PARTE 1: EN EL NOTEBOOK (main.ipynb)
====================================

Ejecutar celdas 1 a 20:
↓
Cargar datos (stroke_dataset.csv)
↓
Explorar y limpiar datos (EDA)
↓
Entrenar modelos (Regresión Logística, Random Forest)
↓
Optimizar hiperparámetros (GridSearchCV)
↓
Obtener el mejor modelo (grid.best_estimator_)
↓
GUARDAR EN DISCO: joblib.dump(best_model, "modelo.pkl")
↓
Archivo "modelo.pkl" aparece en la carpeta del proyecto


PARTE 2: EN LA APP (app.py)
============================

Usuario ejecuta: streamlit run app.py
↓
App inicia
↓
CARGAR DEL DISCO: model = joblib.load("modelo.pkl")
↓
El modelo está en memoria, listo para usar
↓
Usuario ingresa valores en el formulario
↓
User hace clic en "Predecir"
↓
App prepara array de 14 features
↓
App llama: prediction = model.predict(input_data)
↓
El modelo hace predicción INSTANTÁNEAMENTE (sin reentrenar)
↓
App muestra resultado


================================================================================
ESTRUCTURA DE ARCHIVOS
================================================================================

AprendizajeSupervisado_Enrique/
├── main.ipynb              ← Notebook donde se entrena el modelo
├── app.py                  ← App que carga el modelo
├── modelo.pkl              ← ← ← AQUÍ SE GUARDA EL MODELO
├── stroke_dataset.csv      ← Datos originales
├── requeriments.txt        ← Dependencias
└── README.md               ← Documentación


================================================================================
TAMAÑO Y EFICIENCIA
================================================================================

¿Cuánto ocupa modelo.pkl?
- Típicamente: 5-50 MB (depende del modelo)
- En nuestro caso: ~5 MB

¿Por qué es eficiente?
- El modelo ENTRENADO se comprime en formato binario
- Es mucho más pequeño que si guardáramos los datos originales
- Se carga en memoria muy rápidamente (< 1 segundo)
- Permite predicciones instantáneas


================================================================================
¿QUÉ OCURRE SI NO EXISTE modelo.pkl?
================================================================================

En app.py hay esta verificación:

```python
if not os.path.exists("modelo.pkl"):
    st.error("archivo 'modelo.pkl' no encontrado...")
    st.stop()
```

Si modelo.pkl NO existe:
1. App muestra error (rojo)
2. App se detiene (no continúa)
3. Usuario no puede usar la app

SOLUCIÓN: Ejecutar todas las celdas de main.ipynb primero


================================================================================
FLUJO DE DATOS EN PREDICCIÓN
================================================================================

1. Usuario en app.py ingresa:
   Edad: 55
   IMC: 26
   Glucosa: 120
   ... (más 11 features)

2. App convierte a array de 14 números:
   [55, 0, 0, 120, 26, 1, 1, 1, 0, 0, 1, 0, 0, 1]

3. App envía al modelo:
   prediction = model.predict([55, 0, 0, 120, 26, 1, 1, 1, 0, 0, 1, 0, 0, 1])

4. Dentro de modelo.pkl ocurre:
   
   Árbol 1: Comienza predicción (sigue reglas aprendidas)
   ├─ ¿feature_5 > 0.5? Sí → va a rama izquierda
   ├─ ¿feature_12 < 0.3? No → va a rama derecha
   └─ Resultado árbol 1: "SÍ ictus" (voto = 1)
   
   Árbol 2: Comienza predicción
   ├─ ¿feature_3 > 100? Sí → va a rama izquierda
   ├─ ¿feature_7 > 0.8? Sí → va a rama izquierda
   └─ Resultado árbol 2: "NO ictus" (voto = 0)
   
   ... (Árboles 3 a 200 hacen lo mismo)
   
   AGREGACIÓN: Votos = [150 votos "SÍ", 50 votos "NO"]
   DECISIÓN FINAL: "SÍ hay riesgo" (1)
   CONFIANZA: 150/200 = 75% de probabilidad

5. Model devuelve:
   prediction = 1
   prediction_proba = [0.25, 0.75]  (25% sin riesgo, 75% con riesgo)

6. App muestra:
   "⚠️ Riesgo ALTO de Ictus (Probabilidad: 75%)"


================================================================================
PUNTOS CLAVE
================================================================================

✓ modelo.pkl contiene el MODELO ENTRENADO (no los datos)
✓ Se crea ejecutando las celdas del notebook
✓ Se guarda con joblib.dump()
✓ Se carga con joblib.load()
✓ Permite predicciones instantáneas sin reentrenar
✓ Es portable (se puede compartir y usar en otras máquinas)
✓ Si no existe, app.py no funciona
✓ Su validez depende de que los datos de entrada (14 features) sean correctos


================================================================================
ERRORES COMUNES Y SOLUCIONES
================================================================================

ERROR 1: "FileNotFoundError: modelo.pkl"
CAUSA: No ejecutaste el notebook o no se guardó el modelo
SOLUCIÓN: Ejecuta todos las celdas del notebook (main.ipynb)

ERROR 2: "X has 9 features but RandomForestClassifier is expecting 14"
CAUSA: App está enviando número incorrecto de features
SOLUCIÓN: Asegurate de que app.py incluye TODOS los 14 features en el array

ERROR 3: "Expected 1D array, got 2D array"
CAUSA: El array está mal formado
SOLUCIÓN: Usa np.array([[...]]) con doble corchete (es un array 2D con 1 fila)

ERROR 4: Predicciones inconsistentes
CAUSA: Features en orden incorrecto o valores inválidos
SOLUCIÓN: Verifica que el orden en app.py coincida con main.ipynb


================================================================================
FIN DE LA EXPLICACIÓN
================================================================================
